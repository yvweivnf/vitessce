{"ast":null,"code":"import _slicedToArray from \"C:\\\\Users\\\\wkuo\\\\Documents\\\\vitessce-forked-v1.2.2\\\\vitessce\\\\node_modules\\\\babel-preset-react-app\\\\node_modules\\\\@babel\\\\runtime/helpers/esm/slicedToArray\";\nimport _toConsumableArray from \"C:\\\\Users\\\\wkuo\\\\Documents\\\\vitessce-forked-v1.2.2\\\\vitessce\\\\node_modules\\\\babel-preset-react-app\\\\node_modules\\\\@babel\\\\runtime/helpers/esm/toConsumableArray\";\nimport _createForOfIteratorHelper from \"C:\\\\Users\\\\wkuo\\\\Documents\\\\vitessce-forked-v1.2.2\\\\vitessce\\\\node_modules\\\\babel-preset-react-app\\\\node_modules\\\\@babel\\\\runtime/helpers/esm/createForOfIteratorHelper\";\nimport _classCallCheck from \"C:\\\\Users\\\\wkuo\\\\Documents\\\\vitessce-forked-v1.2.2\\\\vitessce\\\\node_modules\\\\babel-preset-react-app\\\\node_modules\\\\@babel\\\\runtime/helpers/esm/classCallCheck\";\nimport _createClass from \"C:\\\\Users\\\\wkuo\\\\Documents\\\\vitessce-forked-v1.2.2\\\\vitessce\\\\node_modules\\\\babel-preset-react-app\\\\node_modules\\\\@babel\\\\runtime/helpers/esm/createClass\";\nimport _inherits from \"C:\\\\Users\\\\wkuo\\\\Documents\\\\vitessce-forked-v1.2.2\\\\vitessce\\\\node_modules\\\\babel-preset-react-app\\\\node_modules\\\\@babel\\\\runtime/helpers/esm/inherits\";\nimport _createSuper from \"C:\\\\Users\\\\wkuo\\\\Documents\\\\vitessce-forked-v1.2.2\\\\vitessce\\\\node_modules\\\\babel-preset-react-app\\\\node_modules\\\\@babel\\\\runtime/helpers/esm/createSuper\";\nimport { fieldIntersection, hash, hasIntersection, isEmpty, keys, some } from '../../util';\nimport { requiresSelectionId } from '../selection';\nimport { AggregateNode } from './aggregate';\nimport { BinNode } from './bin';\nimport { OutputNode } from './dataflow';\nimport { FacetNode } from './facet';\nimport { FilterNode } from './filter';\nimport { ParseNode } from './formatparse';\nimport { IdentifierNode } from './identifier';\nimport { BottomUpOptimizer, isDataSourceNode, Optimizer, TopDownOptimizer } from './optimizer';\nimport { SourceNode } from './source';\nimport { TimeUnitNode } from './timeunit';\n/**\n * Merge identical nodes at forks by comparing hashes.\n *\n * Does not need to iterate from leaves so we implement this with recursion as it's a bit simpler.\n */\n\nexport var MergeIdenticalNodes = /*#__PURE__*/function (_TopDownOptimizer) {\n  _inherits(MergeIdenticalNodes, _TopDownOptimizer);\n\n  var _super = _createSuper(MergeIdenticalNodes);\n\n  function MergeIdenticalNodes() {\n    _classCallCheck(this, MergeIdenticalNodes);\n\n    return _super.apply(this, arguments);\n  }\n\n  _createClass(MergeIdenticalNodes, [{\n    key: \"mergeNodes\",\n    value: function mergeNodes(parent, nodes) {\n      var mergedNode = nodes.shift();\n\n      var _iterator = _createForOfIteratorHelper(nodes),\n          _step;\n\n      try {\n        for (_iterator.s(); !(_step = _iterator.n()).done;) {\n          var node = _step.value;\n          parent.removeChild(node);\n          node.parent = mergedNode;\n          node.remove();\n        }\n      } catch (err) {\n        _iterator.e(err);\n      } finally {\n        _iterator.f();\n      }\n    }\n  }, {\n    key: \"run\",\n    value: function run(node) {\n      var hashes = node.children.map(function (x) {\n        return x.hash();\n      });\n      var buckets = {};\n\n      for (var i = 0; i < hashes.length; i++) {\n        if (buckets[hashes[i]] === undefined) {\n          buckets[hashes[i]] = [node.children[i]];\n        } else {\n          buckets[hashes[i]].push(node.children[i]);\n        }\n      }\n\n      var _iterator2 = _createForOfIteratorHelper(keys(buckets)),\n          _step2;\n\n      try {\n        for (_iterator2.s(); !(_step2 = _iterator2.n()).done;) {\n          var k = _step2.value;\n\n          if (buckets[k].length > 1) {\n            this.setModified();\n            this.mergeNodes(node, buckets[k]);\n          }\n        }\n      } catch (err) {\n        _iterator2.e(err);\n      } finally {\n        _iterator2.f();\n      }\n    }\n  }]);\n\n  return MergeIdenticalNodes;\n}(TopDownOptimizer);\n/**\n * Optimizer that removes identifier nodes that are not needed for selections.\n */\n\nexport var RemoveUnnecessaryIdentifierNodes = /*#__PURE__*/function (_TopDownOptimizer2) {\n  _inherits(RemoveUnnecessaryIdentifierNodes, _TopDownOptimizer2);\n\n  var _super2 = _createSuper(RemoveUnnecessaryIdentifierNodes);\n\n  function RemoveUnnecessaryIdentifierNodes(model) {\n    var _this;\n\n    _classCallCheck(this, RemoveUnnecessaryIdentifierNodes);\n\n    _this = _super2.call(this);\n    _this.requiresSelectionId = model && requiresSelectionId(model);\n    return _this;\n  }\n\n  _createClass(RemoveUnnecessaryIdentifierNodes, [{\n    key: \"run\",\n    value: function run(node) {\n      if (node instanceof IdentifierNode) {\n        // Only preserve IdentifierNodes if we have default discrete selections\n        // in our model tree, and if the nodes come after tuple producing nodes.\n        if (!(this.requiresSelectionId && (isDataSourceNode(node.parent) || node.parent instanceof AggregateNode || node.parent instanceof ParseNode))) {\n          this.setModified();\n          node.remove();\n        }\n      }\n    }\n  }]);\n\n  return RemoveUnnecessaryIdentifierNodes;\n}(TopDownOptimizer);\n/**\n * Removes duplicate time unit nodes (as determined by the name of the output field) that may be generated due to\n * selections projected over time units. Only keeps the first time unit in any branch.\n *\n * This optimizer is a custom top down optimizer that keep track of produced fields in a branch.\n */\n\nexport var RemoveDuplicateTimeUnits = /*#__PURE__*/function (_Optimizer) {\n  _inherits(RemoveDuplicateTimeUnits, _Optimizer);\n\n  var _super3 = _createSuper(RemoveDuplicateTimeUnits);\n\n  function RemoveDuplicateTimeUnits() {\n    _classCallCheck(this, RemoveDuplicateTimeUnits);\n\n    return _super3.apply(this, arguments);\n  }\n\n  _createClass(RemoveDuplicateTimeUnits, [{\n    key: \"optimize\",\n    value: function optimize(node) {\n      this.run(node, new Set());\n      return this.modifiedFlag;\n    }\n  }, {\n    key: \"run\",\n    value: function run(node, timeUnitFields) {\n      var producedFields = new Set();\n\n      if (node instanceof TimeUnitNode) {\n        producedFields = node.producedFields();\n\n        if (hasIntersection(producedFields, timeUnitFields)) {\n          this.setModified();\n          node.removeFormulas(timeUnitFields);\n\n          if (node.producedFields.length === 0) {\n            node.remove();\n          }\n        }\n      }\n\n      var _iterator3 = _createForOfIteratorHelper(node.children),\n          _step3;\n\n      try {\n        for (_iterator3.s(); !(_step3 = _iterator3.n()).done;) {\n          var child = _step3.value;\n          this.run(child, new Set([].concat(_toConsumableArray(timeUnitFields), _toConsumableArray(producedFields))));\n        }\n      } catch (err) {\n        _iterator3.e(err);\n      } finally {\n        _iterator3.f();\n      }\n    }\n  }]);\n\n  return RemoveDuplicateTimeUnits;\n}(Optimizer);\n/**\n * Remove output nodes that are not required.\n */\n\nexport var RemoveUnnecessaryOutputNodes = /*#__PURE__*/function (_TopDownOptimizer3) {\n  _inherits(RemoveUnnecessaryOutputNodes, _TopDownOptimizer3);\n\n  var _super4 = _createSuper(RemoveUnnecessaryOutputNodes);\n\n  function RemoveUnnecessaryOutputNodes() {\n    _classCallCheck(this, RemoveUnnecessaryOutputNodes);\n\n    return _super4.call(this);\n  }\n\n  _createClass(RemoveUnnecessaryOutputNodes, [{\n    key: \"run\",\n    value: function run(node) {\n      if (node instanceof OutputNode && !node.isRequired()) {\n        this.setModified();\n        node.remove();\n      }\n    }\n  }]);\n\n  return RemoveUnnecessaryOutputNodes;\n}(TopDownOptimizer);\n/**\n * Move parse nodes up to forks and merges them if possible.\n */\n\nexport var MoveParseUp = /*#__PURE__*/function (_BottomUpOptimizer) {\n  _inherits(MoveParseUp, _BottomUpOptimizer);\n\n  var _super5 = _createSuper(MoveParseUp);\n\n  function MoveParseUp() {\n    _classCallCheck(this, MoveParseUp);\n\n    return _super5.apply(this, arguments);\n  }\n\n  _createClass(MoveParseUp, [{\n    key: \"run\",\n    value: function run(node) {\n      if (isDataSourceNode(node)) {\n        return;\n      }\n\n      if (node.numChildren() > 1) {\n        // Don't move parse further up but continue with parent.\n        return;\n      }\n\n      var _iterator4 = _createForOfIteratorHelper(node.children),\n          _step4;\n\n      try {\n        for (_iterator4.s(); !(_step4 = _iterator4.n()).done;) {\n          var child = _step4.value;\n\n          if (child instanceof ParseNode) {\n            if (node instanceof ParseNode) {\n              this.setModified();\n              node.merge(child);\n            } else {\n              // Don't swap with nodes that produce something that the parse node depends on (e.g. lookup).\n              if (fieldIntersection(node.producedFields(), child.dependentFields())) {\n                continue;\n              }\n\n              this.setModified();\n              child.swapWithParent();\n            }\n          }\n        }\n      } catch (err) {\n        _iterator4.e(err);\n      } finally {\n        _iterator4.f();\n      }\n\n      return;\n    }\n  }]);\n\n  return MoveParseUp;\n}(BottomUpOptimizer);\n/**\n * Inserts an intermediate ParseNode containing all non-conflicting parse fields and removes the empty ParseNodes.\n *\n * We assume that dependent paths that do not have a parse node can be just merged.\n */\n\nexport var MergeParse = /*#__PURE__*/function (_BottomUpOptimizer2) {\n  _inherits(MergeParse, _BottomUpOptimizer2);\n\n  var _super6 = _createSuper(MergeParse);\n\n  function MergeParse() {\n    _classCallCheck(this, MergeParse);\n\n    return _super6.apply(this, arguments);\n  }\n\n  _createClass(MergeParse, [{\n    key: \"run\",\n    value: function run(node) {\n      var originalChildren = _toConsumableArray(node.children);\n\n      var parseChildren = node.children.filter(function (child) {\n        return child instanceof ParseNode;\n      });\n\n      if (node.numChildren() > 1 && parseChildren.length >= 1) {\n        var commonParse = {};\n        var conflictingParse = new Set();\n\n        var _iterator5 = _createForOfIteratorHelper(parseChildren),\n            _step5;\n\n        try {\n          for (_iterator5.s(); !(_step5 = _iterator5.n()).done;) {\n            var parseNode = _step5.value;\n            var parse = parseNode.parse;\n\n            var _iterator9 = _createForOfIteratorHelper(keys(parse)),\n                _step9;\n\n            try {\n              for (_iterator9.s(); !(_step9 = _iterator9.n()).done;) {\n                var k = _step9.value;\n\n                if (!(k in commonParse)) {\n                  commonParse[k] = parse[k];\n                } else if (commonParse[k] !== parse[k]) {\n                  conflictingParse.add(k);\n                }\n              }\n            } catch (err) {\n              _iterator9.e(err);\n            } finally {\n              _iterator9.f();\n            }\n          }\n        } catch (err) {\n          _iterator5.e(err);\n        } finally {\n          _iterator5.f();\n        }\n\n        var _iterator6 = _createForOfIteratorHelper(conflictingParse),\n            _step6;\n\n        try {\n          for (_iterator6.s(); !(_step6 = _iterator6.n()).done;) {\n            var field = _step6.value;\n            delete commonParse[field];\n          }\n        } catch (err) {\n          _iterator6.e(err);\n        } finally {\n          _iterator6.f();\n        }\n\n        if (!isEmpty(commonParse)) {\n          this.setModified();\n          var mergedParseNode = new ParseNode(node, commonParse);\n\n          var _iterator7 = _createForOfIteratorHelper(originalChildren),\n              _step7;\n\n          try {\n            for (_iterator7.s(); !(_step7 = _iterator7.n()).done;) {\n              var childNode = _step7.value;\n\n              if (childNode instanceof ParseNode) {\n                var _iterator8 = _createForOfIteratorHelper(keys(commonParse)),\n                    _step8;\n\n                try {\n                  for (_iterator8.s(); !(_step8 = _iterator8.n()).done;) {\n                    var key = _step8.value;\n                    delete childNode.parse[key];\n                  }\n                } catch (err) {\n                  _iterator8.e(err);\n                } finally {\n                  _iterator8.f();\n                }\n              }\n\n              node.removeChild(childNode);\n              childNode.parent = mergedParseNode; // remove empty parse nodes\n\n              if (childNode instanceof ParseNode && keys(childNode.parse).length === 0) {\n                childNode.remove();\n              }\n            }\n          } catch (err) {\n            _iterator7.e(err);\n          } finally {\n            _iterator7.f();\n          }\n        }\n      }\n    }\n  }]);\n\n  return MergeParse;\n}(BottomUpOptimizer);\n/**\n * Repeatedly remove leaf nodes that are not output or facet nodes.\n * The reason is that we don't need subtrees that don't have any output nodes.\n * Facet nodes are needed for the row or column domains.\n */\n\nexport var RemoveUnusedSubtrees = /*#__PURE__*/function (_BottomUpOptimizer3) {\n  _inherits(RemoveUnusedSubtrees, _BottomUpOptimizer3);\n\n  var _super7 = _createSuper(RemoveUnusedSubtrees);\n\n  function RemoveUnusedSubtrees() {\n    _classCallCheck(this, RemoveUnusedSubtrees);\n\n    return _super7.apply(this, arguments);\n  }\n\n  _createClass(RemoveUnusedSubtrees, [{\n    key: \"run\",\n    value: function run(node) {\n      if (node instanceof OutputNode || node.numChildren() > 0 || node instanceof FacetNode) {// no need to continue with parent because it is output node or will have children (there was a fork)\n      } else if (node instanceof SourceNode) {// ignore empty unused sources as they will be removed in optimizationDataflowHelper\n      } else {\n        this.setModified();\n        node.remove();\n      }\n    }\n  }]);\n\n  return RemoveUnusedSubtrees;\n}(BottomUpOptimizer);\n/**\n * Merge adjacent time unit nodes.\n */\n\nexport var MergeTimeUnits = /*#__PURE__*/function (_BottomUpOptimizer4) {\n  _inherits(MergeTimeUnits, _BottomUpOptimizer4);\n\n  var _super8 = _createSuper(MergeTimeUnits);\n\n  function MergeTimeUnits() {\n    _classCallCheck(this, MergeTimeUnits);\n\n    return _super8.apply(this, arguments);\n  }\n\n  _createClass(MergeTimeUnits, [{\n    key: \"run\",\n    value: function run(node) {\n      var timeUnitChildren = node.children.filter(function (x) {\n        return x instanceof TimeUnitNode;\n      });\n      var combination = timeUnitChildren.pop();\n\n      var _iterator10 = _createForOfIteratorHelper(timeUnitChildren),\n          _step10;\n\n      try {\n        for (_iterator10.s(); !(_step10 = _iterator10.n()).done;) {\n          var timeUnit = _step10.value;\n          this.setModified();\n          combination.merge(timeUnit);\n        }\n      } catch (err) {\n        _iterator10.e(err);\n      } finally {\n        _iterator10.f();\n      }\n    }\n  }]);\n\n  return MergeTimeUnits;\n}(BottomUpOptimizer);\nexport var MergeAggregates = /*#__PURE__*/function (_BottomUpOptimizer5) {\n  _inherits(MergeAggregates, _BottomUpOptimizer5);\n\n  var _super9 = _createSuper(MergeAggregates);\n\n  function MergeAggregates() {\n    _classCallCheck(this, MergeAggregates);\n\n    return _super9.apply(this, arguments);\n  }\n\n  _createClass(MergeAggregates, [{\n    key: \"run\",\n    value: function run(node) {\n      var aggChildren = node.children.filter(function (child) {\n        return child instanceof AggregateNode;\n      }); // Object which we'll use to map the fields which an aggregate is grouped by to\n      // the set of aggregates with that grouping. This is useful as only aggregates\n      // with the same group by can be merged\n\n      var groupedAggregates = {}; // Build groupedAggregates\n\n      var _iterator11 = _createForOfIteratorHelper(aggChildren),\n          _step11;\n\n      try {\n        for (_iterator11.s(); !(_step11 = _iterator11.n()).done;) {\n          var agg = _step11.value;\n          var groupBys = hash(agg.groupBy);\n\n          if (!(groupBys in groupedAggregates)) {\n            groupedAggregates[groupBys] = [];\n          }\n\n          groupedAggregates[groupBys].push(agg);\n        } // Merge aggregateNodes with same key in groupedAggregates\n\n      } catch (err) {\n        _iterator11.e(err);\n      } finally {\n        _iterator11.f();\n      }\n\n      var _iterator12 = _createForOfIteratorHelper(keys(groupedAggregates)),\n          _step12;\n\n      try {\n        for (_iterator12.s(); !(_step12 = _iterator12.n()).done;) {\n          var group = _step12.value;\n          var mergeableAggs = groupedAggregates[group];\n\n          if (mergeableAggs.length > 1) {\n            var mergedAggs = mergeableAggs.pop();\n\n            var _iterator13 = _createForOfIteratorHelper(mergeableAggs),\n                _step13;\n\n            try {\n              for (_iterator13.s(); !(_step13 = _iterator13.n()).done;) {\n                var _agg = _step13.value;\n\n                if (mergedAggs.merge(_agg)) {\n                  node.removeChild(_agg);\n                  _agg.parent = mergedAggs;\n\n                  _agg.remove();\n\n                  this.setModified();\n                }\n              }\n            } catch (err) {\n              _iterator13.e(err);\n            } finally {\n              _iterator13.f();\n            }\n          }\n        }\n      } catch (err) {\n        _iterator12.e(err);\n      } finally {\n        _iterator12.f();\n      }\n    }\n  }]);\n\n  return MergeAggregates;\n}(BottomUpOptimizer);\n/**\n * Merge bin nodes and move them up through forks. Stop at filters, parse, identifier as we want them to stay before the bin node.\n */\n\nexport var MergeBins = /*#__PURE__*/function (_BottomUpOptimizer6) {\n  _inherits(MergeBins, _BottomUpOptimizer6);\n\n  var _super10 = _createSuper(MergeBins);\n\n  function MergeBins(model) {\n    var _this2;\n\n    _classCallCheck(this, MergeBins);\n\n    _this2 = _super10.call(this);\n    _this2.model = model;\n    return _this2;\n  }\n\n  _createClass(MergeBins, [{\n    key: \"run\",\n    value: function run(node) {\n      var moveBinsUp = !(isDataSourceNode(node) || node instanceof FilterNode || node instanceof ParseNode || node instanceof IdentifierNode);\n      var promotableBins = [];\n      var remainingBins = [];\n\n      var _iterator14 = _createForOfIteratorHelper(node.children),\n          _step14;\n\n      try {\n        for (_iterator14.s(); !(_step14 = _iterator14.n()).done;) {\n          var child = _step14.value;\n\n          if (child instanceof BinNode) {\n            if (moveBinsUp && !fieldIntersection(node.producedFields(), child.dependentFields())) {\n              promotableBins.push(child);\n            } else {\n              remainingBins.push(child);\n            }\n          }\n        }\n      } catch (err) {\n        _iterator14.e(err);\n      } finally {\n        _iterator14.f();\n      }\n\n      if (promotableBins.length > 0) {\n        var promotedBin = promotableBins.pop();\n\n        var _iterator15 = _createForOfIteratorHelper(promotableBins),\n            _step15;\n\n        try {\n          for (_iterator15.s(); !(_step15 = _iterator15.n()).done;) {\n            var bin = _step15.value;\n            promotedBin.merge(bin, this.model.renameSignal.bind(this.model));\n          }\n        } catch (err) {\n          _iterator15.e(err);\n        } finally {\n          _iterator15.f();\n        }\n\n        this.setModified();\n\n        if (node instanceof BinNode) {\n          node.merge(promotedBin, this.model.renameSignal.bind(this.model));\n        } else {\n          promotedBin.swapWithParent();\n        }\n      }\n\n      if (remainingBins.length > 1) {\n        var remainingBin = remainingBins.pop();\n\n        var _iterator16 = _createForOfIteratorHelper(remainingBins),\n            _step16;\n\n        try {\n          for (_iterator16.s(); !(_step16 = _iterator16.n()).done;) {\n            var _bin = _step16.value;\n            remainingBin.merge(_bin, this.model.renameSignal.bind(this.model));\n          }\n        } catch (err) {\n          _iterator16.e(err);\n        } finally {\n          _iterator16.f();\n        }\n\n        this.setModified();\n      }\n    }\n  }]);\n\n  return MergeBins;\n}(BottomUpOptimizer);\n/**\n * This optimizer takes output nodes that are at a fork and moves them before the fork.\n *\n * The algorithm iterates over the children and tries to find the last output node in a chain of output nodes.\n * It then moves all output nodes before that main output node. All other children (and the children of the output nodes)\n * are inserted after the main output node.\n */\n\nexport var MergeOutputs = /*#__PURE__*/function (_BottomUpOptimizer7) {\n  _inherits(MergeOutputs, _BottomUpOptimizer7);\n\n  var _super11 = _createSuper(MergeOutputs);\n\n  function MergeOutputs() {\n    _classCallCheck(this, MergeOutputs);\n\n    return _super11.apply(this, arguments);\n  }\n\n  _createClass(MergeOutputs, [{\n    key: \"run\",\n    value: function run(node) {\n      var children = _toConsumableArray(node.children);\n\n      var hasOutputChild = some(children, function (child) {\n        return child instanceof OutputNode;\n      });\n\n      if (!hasOutputChild || node.numChildren() <= 1) {\n        return;\n      }\n\n      var otherChildren = []; // The output node we will connect all other nodes to.\n      // Output nodes will be added before the new node, other nodes after.\n\n      var mainOutput;\n\n      var _iterator17 = _createForOfIteratorHelper(children),\n          _step17;\n\n      try {\n        for (_iterator17.s(); !(_step17 = _iterator17.n()).done;) {\n          var _child = _step17.value;\n\n          if (_child instanceof OutputNode) {\n            var lastOutput = _child;\n\n            while (lastOutput.numChildren() === 1) {\n              var _lastOutput$children = _slicedToArray(lastOutput.children, 1),\n                  theChild = _lastOutput$children[0];\n\n              if (theChild instanceof OutputNode) {\n                lastOutput = theChild;\n              } else {\n                break;\n              }\n            }\n\n            otherChildren.push.apply(otherChildren, _toConsumableArray(lastOutput.children));\n\n            if (mainOutput) {\n              // Move the output nodes before the mainOutput. We do this by setting\n              // the parent of the first not to the parent of the main output and\n              // the main output's parent to the last output.\n              // note: the child is the first output\n              node.removeChild(_child);\n              _child.parent = mainOutput.parent;\n              mainOutput.parent.removeChild(mainOutput);\n              mainOutput.parent = lastOutput;\n              this.setModified();\n            } else {\n              mainOutput = lastOutput;\n            }\n          } else {\n            otherChildren.push(_child);\n          }\n        }\n      } catch (err) {\n        _iterator17.e(err);\n      } finally {\n        _iterator17.f();\n      }\n\n      if (otherChildren.length) {\n        this.setModified();\n\n        var _iterator18 = _createForOfIteratorHelper(otherChildren),\n            _step18;\n\n        try {\n          for (_iterator18.s(); !(_step18 = _iterator18.n()).done;) {\n            var child = _step18.value;\n            child.parent.removeChild(child);\n            child.parent = mainOutput;\n          }\n        } catch (err) {\n          _iterator18.e(err);\n        } finally {\n          _iterator18.f();\n        }\n      }\n    }\n  }]);\n\n  return MergeOutputs;\n}(BottomUpOptimizer);","map":{"version":3,"sources":["../../../../src/compile/data/optimizers.ts"],"names":[],"mappings":";;;;;;;AACA,SAAc,iBAAd,EAAiC,IAAjC,EAAuC,eAAvC,EAAwD,OAAxD,EAAiE,IAAjE,EAAuE,IAAvE,QAAkF,YAAlF;AAEA,SAAQ,mBAAR,QAAkC,cAAlC;AACA,SAAQ,aAAR,QAA4B,aAA5B;AACA,SAAQ,OAAR,QAAsB,OAAtB;AACA,SAAsB,UAAtB,QAAuC,YAAvC;AACA,SAAQ,SAAR,QAAwB,SAAxB;AACA,SAAQ,UAAR,QAAyB,UAAzB;AACA,SAAQ,SAAR,QAAwB,eAAxB;AACA,SAAQ,cAAR,QAA6B,cAA7B;AACA,SAAQ,iBAAR,EAA2B,gBAA3B,EAA6C,SAA7C,EAAwD,gBAAxD,QAA+E,aAA/E;AACA,SAAQ,UAAR,QAAyB,UAAzB;AACA,SAAQ,YAAR,QAA2B,YAA3B;AAEA;;;;;;AAKA,WAAa,mBAAb;AAAA;;AAAA;;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA,+BACoB,MADpB,EAC0C,KAD1C,EAC+D;AAC3D,UAAM,UAAU,GAAG,KAAK,CAAC,KAAN,EAAnB;;AAD2D,iDAExC,KAFwC;AAAA;;AAAA;AAE3D,4DAA0B;AAAA,cAAf,IAAe;AACxB,UAAA,MAAM,CAAC,WAAP,CAAmB,IAAnB;AACA,UAAA,IAAI,CAAC,MAAL,GAAc,UAAd;AACA,UAAA,IAAI,CAAC,MAAL;AACD;AAN0D;AAAA;AAAA;AAAA;AAAA;AAO5D;AARH;AAAA;AAAA,wBAUa,IAVb,EAU+B;AAC3B,UAAM,MAAM,GAAG,IAAI,CAAC,QAAL,CAAc,GAAd,CAAkB,UAAA,CAAC;AAAA,eAAI,CAAC,CAAC,IAAF,EAAJ;AAAA,OAAnB,CAAf;AACA,UAAM,OAAO,GAA4B,EAAzC;;AAEA,WAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,MAAM,CAAC,MAA3B,EAAmC,CAAC,EAApC,EAAwC;AACtC,YAAI,OAAO,CAAC,MAAM,CAAC,CAAD,CAAP,CAAP,KAAuB,SAA3B,EAAsC;AACpC,UAAA,OAAO,CAAC,MAAM,CAAC,CAAD,CAAP,CAAP,GAAqB,CAAC,IAAI,CAAC,QAAL,CAAc,CAAd,CAAD,CAArB;AACD,SAFD,MAEO;AACL,UAAA,OAAO,CAAC,MAAM,CAAC,CAAD,CAAP,CAAP,CAAmB,IAAnB,CAAwB,IAAI,CAAC,QAAL,CAAc,CAAd,CAAxB;AACD;AACF;;AAV0B,kDAYX,IAAI,CAAC,OAAD,CAZO;AAAA;;AAAA;AAY3B,+DAA+B;AAAA,cAApB,CAAoB;;AAC7B,cAAI,OAAO,CAAC,CAAD,CAAP,CAAW,MAAX,GAAoB,CAAxB,EAA2B;AACzB,iBAAK,WAAL;AACA,iBAAK,UAAL,CAAgB,IAAhB,EAAsB,OAAO,CAAC,CAAD,CAA7B;AACD;AACF;AAjB0B;AAAA;AAAA;AAAA;AAAA;AAkB5B;AA5BH;;AAAA;AAAA,EAAyC,gBAAzC;AA+BA;;;;AAGA,WAAa,gCAAb;AAAA;;AAAA;;AAGE,4CAAY,KAAZ,EAAwB;AAAA;;AAAA;;AACtB;AACA,UAAK,mBAAL,GAA2B,KAAK,IAAI,mBAAmB,CAAC,KAAD,CAAvD;AAFsB;AAGvB;;AANH;AAAA;AAAA,wBAQa,IARb,EAQ+B;AAC3B,UAAI,IAAI,YAAY,cAApB,EAAoC;AAClC;AACA;AACA,YACE,EACE,KAAK,mBAAL,KACC,gBAAgB,CAAC,IAAI,CAAC,MAAN,CAAhB,IAAiC,IAAI,CAAC,MAAL,YAAuB,aAAxD,IAAyE,IAAI,CAAC,MAAL,YAAuB,SADjG,CADF,CADF,EAKE;AACA,eAAK,WAAL;AACA,UAAA,IAAI,CAAC,MAAL;AACD;AACF;AACF;AAtBH;;AAAA;AAAA,EAAsD,gBAAtD;AAyBA;;;;;;;AAMA,WAAa,wBAAb;AAAA;;AAAA;;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA,6BACkB,IADlB,EACoC;AAChC,WAAK,GAAL,CAAS,IAAT,EAAe,IAAI,GAAJ,EAAf;AAEA,aAAO,KAAK,YAAZ;AACD;AALH;AAAA;AAAA,wBAOa,IAPb,EAOiC,cAPjC,EAO4D;AACxD,UAAI,cAAc,GAAG,IAAI,GAAJ,EAArB;;AAEA,UAAI,IAAI,YAAY,YAApB,EAAkC;AAChC,QAAA,cAAc,GAAG,IAAI,CAAC,cAAL,EAAjB;;AACA,YAAI,eAAe,CAAC,cAAD,EAAiB,cAAjB,CAAnB,EAAqD;AACnD,eAAK,WAAL;AACA,UAAA,IAAI,CAAC,cAAL,CAAoB,cAApB;;AACA,cAAI,IAAI,CAAC,cAAL,CAAoB,MAApB,KAA+B,CAAnC,EAAsC;AACpC,YAAA,IAAI,CAAC,MAAL;AACD;AACF;AACF;;AAZuD,kDAcpC,IAAI,CAAC,QAd+B;AAAA;;AAAA;AAcxD,+DAAmC;AAAA,cAAxB,KAAwB;AACjC,eAAK,GAAL,CAAS,KAAT,EAAgB,IAAI,GAAJ,8BAAY,cAAZ,sBAA+B,cAA/B,GAAhB;AACD;AAhBuD;AAAA;AAAA;AAAA;AAAA;AAiBzD;AAxBH;;AAAA;AAAA,EAA8C,SAA9C;AA2BA;;;;AAGA,WAAa,4BAAb;AAAA;;AAAA;;AACE,0CAAA;AAAA;;AAAA;AAEC;;AAHH;AAAA;AAAA,wBAKa,IALb,EAK+B;AAC3B,UAAI,IAAI,YAAY,UAAhB,IAA8B,CAAC,IAAI,CAAC,UAAL,EAAnC,EAAsD;AACpD,aAAK,WAAL;AACA,QAAA,IAAI,CAAC,MAAL;AACD;AACF;AAVH;;AAAA;AAAA,EAAkD,gBAAlD;AAaA;;;;AAGA,WAAa,WAAb;AAAA;;AAAA;;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA,wBACa,IADb,EAC+B;AAC3B,UAAI,gBAAgB,CAAC,IAAD,CAApB,EAA4B;AAC1B;AACD;;AAED,UAAI,IAAI,CAAC,WAAL,KAAqB,CAAzB,EAA4B;AAC1B;AACA;AACD;;AAR0B,kDAUP,IAAI,CAAC,QAVE;AAAA;;AAAA;AAU3B,+DAAmC;AAAA,cAAxB,KAAwB;;AACjC,cAAI,KAAK,YAAY,SAArB,EAAgC;AAC9B,gBAAI,IAAI,YAAY,SAApB,EAA+B;AAC7B,mBAAK,WAAL;AACA,cAAA,IAAI,CAAC,KAAL,CAAW,KAAX;AACD,aAHD,MAGO;AACL;AACA,kBAAI,iBAAiB,CAAC,IAAI,CAAC,cAAL,EAAD,EAAwB,KAAK,CAAC,eAAN,EAAxB,CAArB,EAAuE;AACrE;AACD;;AACD,mBAAK,WAAL;AACA,cAAA,KAAK,CAAC,cAAN;AACD;AACF;AACF;AAxB0B;AAAA;AAAA;AAAA;AAAA;;AA0B3B;AACD;AA5BH;;AAAA;AAAA,EAAiC,iBAAjC;AA+BA;;;;;;AAKA,WAAa,UAAb;AAAA;;AAAA;;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA,wBACa,IADb,EAC+B;AAC3B,UAAM,gBAAgB,sBAAO,IAAI,CAAC,QAAZ,CAAtB;;AACA,UAAM,aAAa,GAAG,IAAI,CAAC,QAAL,CAAc,MAAd,CAAqB,UAAC,KAAD;AAAA,eAA+B,KAAK,YAAY,SAAhD;AAAA,OAArB,CAAtB;;AAEA,UAAI,IAAI,CAAC,WAAL,KAAqB,CAArB,IAA0B,aAAa,CAAC,MAAd,IAAwB,CAAtD,EAAyD;AACvD,YAAM,WAAW,GAAU,EAA3B;AACA,YAAM,gBAAgB,GAAG,IAAI,GAAJ,EAAzB;;AAFuD,oDAG/B,aAH+B;AAAA;;AAAA;AAGvD,iEAAuC;AAAA,gBAA5B,SAA4B;AACrC,gBAAM,KAAK,GAAG,SAAS,CAAC,KAAxB;;AADqC,wDAErB,IAAI,CAAC,KAAD,CAFiB;AAAA;;AAAA;AAErC,qEAA6B;AAAA,oBAAlB,CAAkB;;AAC3B,oBAAI,EAAE,CAAC,IAAI,WAAP,CAAJ,EAAyB;AACvB,kBAAA,WAAW,CAAC,CAAD,CAAX,GAAiB,KAAK,CAAC,CAAD,CAAtB;AACD,iBAFD,MAEO,IAAI,WAAW,CAAC,CAAD,CAAX,KAAmB,KAAK,CAAC,CAAD,CAA5B,EAAiC;AACtC,kBAAA,gBAAgB,CAAC,GAAjB,CAAqB,CAArB;AACD;AACF;AARoC;AAAA;AAAA;AAAA;AAAA;AAStC;AAZsD;AAAA;AAAA;AAAA;AAAA;;AAAA,oDAcnC,gBAdmC;AAAA;;AAAA;AAcvD,iEAAsC;AAAA,gBAA3B,KAA2B;AACpC,mBAAO,WAAW,CAAC,KAAD,CAAlB;AACD;AAhBsD;AAAA;AAAA;AAAA;AAAA;;AAkBvD,YAAI,CAAC,OAAO,CAAC,WAAD,CAAZ,EAA2B;AACzB,eAAK,WAAL;AACA,cAAM,eAAe,GAAG,IAAI,SAAJ,CAAc,IAAd,EAAoB,WAApB,CAAxB;;AAFyB,sDAGD,gBAHC;AAAA;;AAAA;AAGzB,mEAA0C;AAAA,kBAA/B,SAA+B;;AACxC,kBAAI,SAAS,YAAY,SAAzB,EAAoC;AAAA,4DAChB,IAAI,CAAC,WAAD,CADY;AAAA;;AAAA;AAClC,yEAAqC;AAAA,wBAA1B,GAA0B;AACnC,2BAAO,SAAS,CAAC,KAAV,CAAgB,GAAhB,CAAP;AACD;AAHiC;AAAA;AAAA;AAAA;AAAA;AAInC;;AAED,cAAA,IAAI,CAAC,WAAL,CAAiB,SAAjB;AACA,cAAA,SAAS,CAAC,MAAV,GAAmB,eAAnB,CARwC,CAUxC;;AACA,kBAAI,SAAS,YAAY,SAArB,IAAkC,IAAI,CAAC,SAAS,CAAC,KAAX,CAAJ,CAAsB,MAAtB,KAAiC,CAAvE,EAA0E;AACxE,gBAAA,SAAS,CAAC,MAAV;AACD;AACF;AAjBwB;AAAA;AAAA;AAAA;AAAA;AAkB1B;AACF;AACF;AA3CH;;AAAA;AAAA,EAAgC,iBAAhC;AA8CA;;;;;;AAKA,WAAa,oBAAb;AAAA;;AAAA;;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA,wBACa,IADb,EAC+B;AAC3B,UAAI,IAAI,YAAY,UAAhB,IAA8B,IAAI,CAAC,WAAL,KAAqB,CAAnD,IAAwD,IAAI,YAAY,SAA5E,EAAuF,CACrF;AACD,OAFD,MAEO,IAAI,IAAI,YAAY,UAApB,EAAgC,CACrC;AACD,OAFM,MAEA;AACL,aAAK,WAAL;AACA,QAAA,IAAI,CAAC,MAAL;AACD;AACF;AAVH;;AAAA;AAAA,EAA0C,iBAA1C;AAaA;;;;AAGA,WAAa,cAAb;AAAA;;AAAA;;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA,wBACa,IADb,EAC+B;AAC3B,UAAM,gBAAgB,GAAG,IAAI,CAAC,QAAL,CAAc,MAAd,CAAqB,UAAC,CAAD;AAAA,eAA0B,CAAC,YAAY,YAAvC;AAAA,OAArB,CAAzB;AACA,UAAM,WAAW,GAAG,gBAAgB,CAAC,GAAjB,EAApB;;AAF2B,mDAGJ,gBAHI;AAAA;;AAAA;AAG3B,kEAAyC;AAAA,cAA9B,QAA8B;AACvC,eAAK,WAAL;AACA,UAAA,WAAW,CAAC,KAAZ,CAAkB,QAAlB;AACD;AAN0B;AAAA;AAAA;AAAA;AAAA;AAO5B;AARH;;AAAA;AAAA,EAAoC,iBAApC;AAWA,WAAa,eAAb;AAAA;;AAAA;;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA,wBACa,IADb,EAC+B;AAC3B,UAAM,WAAW,GAAG,IAAI,CAAC,QAAL,CAAc,MAAd,CAAqB,UAAC,KAAD;AAAA,eAAmC,KAAK,YAAY,aAApD;AAAA,OAArB,CAApB,CAD2B,CAG3B;AACA;AACA;;AACA,UAAM,iBAAiB,GAA0B,EAAjD,CAN2B,CAQ3B;;AAR2B,mDAST,WATS;AAAA;;AAAA;AAS3B,kEAA+B;AAAA,cAApB,GAAoB;AAC7B,cAAM,QAAQ,GAAG,IAAI,CAAC,GAAG,CAAC,OAAL,CAArB;;AACA,cAAI,EAAE,QAAQ,IAAI,iBAAd,CAAJ,EAAsC;AACpC,YAAA,iBAAiB,CAAC,QAAD,CAAjB,GAA8B,EAA9B;AACD;;AACD,UAAA,iBAAiB,CAAC,QAAD,CAAjB,CAA4B,IAA5B,CAAiC,GAAjC;AACD,SAf0B,CAiB3B;;AAjB2B;AAAA;AAAA;AAAA;AAAA;;AAAA,mDAkBP,IAAI,CAAC,iBAAD,CAlBG;AAAA;;AAAA;AAkB3B,kEAA6C;AAAA,cAAlC,KAAkC;AAC3C,cAAM,aAAa,GAAG,iBAAiB,CAAC,KAAD,CAAvC;;AACA,cAAI,aAAa,CAAC,MAAd,GAAuB,CAA3B,EAA8B;AAC5B,gBAAM,UAAU,GAAG,aAAa,CAAC,GAAd,EAAnB;;AAD4B,yDAEV,aAFU;AAAA;;AAAA;AAE5B,wEAAiC;AAAA,oBAAtB,IAAsB;;AAC/B,oBAAI,UAAU,CAAC,KAAX,CAAiB,IAAjB,CAAJ,EAA2B;AACzB,kBAAA,IAAI,CAAC,WAAL,CAAiB,IAAjB;AACA,kBAAA,IAAG,CAAC,MAAJ,GAAa,UAAb;;AACA,kBAAA,IAAG,CAAC,MAAJ;;AAEA,uBAAK,WAAL;AACD;AACF;AAV2B;AAAA;AAAA;AAAA;AAAA;AAW7B;AACF;AAhC0B;AAAA;AAAA;AAAA;AAAA;AAiC5B;AAlCH;;AAAA;AAAA,EAAqC,iBAArC;AAqCA;;;;AAGA,WAAa,SAAb;AAAA;;AAAA;;AACE,qBAAoB,KAApB,EAAgC;AAAA;;AAAA;;AAC9B;AADkB,WAAA,KAAA,GAAA,KAAA;AAAY;AAE/B;;AAHH;AAAA;AAAA,wBAKa,IALb,EAK+B;AAC3B,UAAM,UAAU,GAAG,EACjB,gBAAgB,CAAC,IAAD,CAAhB,IACA,IAAI,YAAY,UADhB,IAEA,IAAI,YAAY,SAFhB,IAGA,IAAI,YAAY,cAJC,CAAnB;AAOA,UAAM,cAAc,GAAc,EAAlC;AACA,UAAM,aAAa,GAAc,EAAjC;;AAT2B,mDAWP,IAAI,CAAC,QAXE;AAAA;;AAAA;AAW3B,kEAAmC;AAAA,cAAxB,KAAwB;;AACjC,cAAI,KAAK,YAAY,OAArB,EAA8B;AAC5B,gBAAI,UAAU,IAAI,CAAC,iBAAiB,CAAC,IAAI,CAAC,cAAL,EAAD,EAAwB,KAAK,CAAC,eAAN,EAAxB,CAApC,EAAsF;AACpF,cAAA,cAAc,CAAC,IAAf,CAAoB,KAApB;AACD,aAFD,MAEO;AACL,cAAA,aAAa,CAAC,IAAd,CAAmB,KAAnB;AACD;AACF;AACF;AAnB0B;AAAA;AAAA;AAAA;AAAA;;AAqB3B,UAAI,cAAc,CAAC,MAAf,GAAwB,CAA5B,EAA+B;AAC7B,YAAM,WAAW,GAAG,cAAc,CAAC,GAAf,EAApB;;AAD6B,qDAEX,cAFW;AAAA;;AAAA;AAE7B,oEAAkC;AAAA,gBAAvB,GAAuB;AAChC,YAAA,WAAW,CAAC,KAAZ,CAAkB,GAAlB,EAAuB,KAAK,KAAL,CAAW,YAAX,CAAwB,IAAxB,CAA6B,KAAK,KAAlC,CAAvB;AACD;AAJ4B;AAAA;AAAA;AAAA;AAAA;;AAK7B,aAAK,WAAL;;AACA,YAAI,IAAI,YAAY,OAApB,EAA6B;AAC3B,UAAA,IAAI,CAAC,KAAL,CAAW,WAAX,EAAwB,KAAK,KAAL,CAAW,YAAX,CAAwB,IAAxB,CAA6B,KAAK,KAAlC,CAAxB;AACD,SAFD,MAEO;AACL,UAAA,WAAW,CAAC,cAAZ;AACD;AACF;;AACD,UAAI,aAAa,CAAC,MAAd,GAAuB,CAA3B,EAA8B;AAC5B,YAAM,YAAY,GAAG,aAAa,CAAC,GAAd,EAArB;;AAD4B,qDAEV,aAFU;AAAA;;AAAA;AAE5B,oEAAiC;AAAA,gBAAtB,IAAsB;AAC/B,YAAA,YAAY,CAAC,KAAb,CAAmB,IAAnB,EAAwB,KAAK,KAAL,CAAW,YAAX,CAAwB,IAAxB,CAA6B,KAAK,KAAlC,CAAxB;AACD;AAJ2B;AAAA;AAAA;AAAA;AAAA;;AAK5B,aAAK,WAAL;AACD;AACF;AA7CH;;AAAA;AAAA,EAA+B,iBAA/B;AAgDA;;;;;;;;AAOA,WAAa,YAAb;AAAA;;AAAA;;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA,wBACa,IADb,EAC+B;AAC3B,UAAM,QAAQ,sBAAO,IAAI,CAAC,QAAZ,CAAd;;AACA,UAAM,cAAc,GAAG,IAAI,CAAC,QAAD,EAAW,UAAA,KAAK;AAAA,eAAI,KAAK,YAAY,UAArB;AAAA,OAAhB,CAA3B;;AAEA,UAAI,CAAC,cAAD,IAAmB,IAAI,CAAC,WAAL,MAAsB,CAA7C,EAAgD;AAC9C;AACD;;AAED,UAAM,aAAa,GAAmB,EAAtC,CAR2B,CAU3B;AACA;;AACA,UAAI,UAAJ;;AAZ2B,mDAcP,QAdO;AAAA;;AAAA;AAc3B,kEAA8B;AAAA,cAAnB,MAAmB;;AAC5B,cAAI,MAAK,YAAY,UAArB,EAAiC;AAC/B,gBAAI,UAAU,GAAG,MAAjB;;AAEA,mBAAO,UAAU,CAAC,WAAX,OAA6B,CAApC,EAAuC;AAAA,wDAClB,UAAU,CAAC,QADO;AAAA,kBAC9B,QAD8B;;AAErC,kBAAI,QAAQ,YAAY,UAAxB,EAAoC;AAClC,gBAAA,UAAU,GAAG,QAAb;AACD,eAFD,MAEO;AACL;AACD;AACF;;AAED,YAAA,aAAa,CAAC,IAAd,OAAA,aAAa,qBAAS,UAAU,CAAC,QAApB,EAAb;;AAEA,gBAAI,UAAJ,EAAgB;AACd;AACA;AACA;AAEA;AACA,cAAA,IAAI,CAAC,WAAL,CAAiB,MAAjB;AACA,cAAA,MAAK,CAAC,MAAN,GAAe,UAAU,CAAC,MAA1B;AAEA,cAAA,UAAU,CAAC,MAAX,CAAkB,WAAlB,CAA8B,UAA9B;AACA,cAAA,UAAU,CAAC,MAAX,GAAoB,UAApB;AAEA,mBAAK,WAAL;AACD,aAbD,MAaO;AACL,cAAA,UAAU,GAAG,UAAb;AACD;AACF,WA9BD,MA8BO;AACL,YAAA,aAAa,CAAC,IAAd,CAAmB,MAAnB;AACD;AACF;AAhD0B;AAAA;AAAA;AAAA;AAAA;;AAkD3B,UAAI,aAAa,CAAC,MAAlB,EAA0B;AACxB,aAAK,WAAL;;AADwB,qDAEJ,aAFI;AAAA;;AAAA;AAExB,oEAAmC;AAAA,gBAAxB,KAAwB;AACjC,YAAA,KAAK,CAAC,MAAN,CAAa,WAAb,CAAyB,KAAzB;AACA,YAAA,KAAK,CAAC,MAAN,GAAe,UAAf;AACD;AALuB;AAAA;AAAA;AAAA;AAAA;AAMzB;AACF;AA1DH;;AAAA;AAAA,EAAkC,iBAAlC","sourceRoot":"","sourcesContent":["import { fieldIntersection, hash, hasIntersection, isEmpty, keys, some } from '../../util';\nimport { requiresSelectionId } from '../selection';\nimport { AggregateNode } from './aggregate';\nimport { BinNode } from './bin';\nimport { OutputNode } from './dataflow';\nimport { FacetNode } from './facet';\nimport { FilterNode } from './filter';\nimport { ParseNode } from './formatparse';\nimport { IdentifierNode } from './identifier';\nimport { BottomUpOptimizer, isDataSourceNode, Optimizer, TopDownOptimizer } from './optimizer';\nimport { SourceNode } from './source';\nimport { TimeUnitNode } from './timeunit';\n/**\n * Merge identical nodes at forks by comparing hashes.\n *\n * Does not need to iterate from leaves so we implement this with recursion as it's a bit simpler.\n */\nexport class MergeIdenticalNodes extends TopDownOptimizer {\n    mergeNodes(parent, nodes) {\n        const mergedNode = nodes.shift();\n        for (const node of nodes) {\n            parent.removeChild(node);\n            node.parent = mergedNode;\n            node.remove();\n        }\n    }\n    run(node) {\n        const hashes = node.children.map(x => x.hash());\n        const buckets = {};\n        for (let i = 0; i < hashes.length; i++) {\n            if (buckets[hashes[i]] === undefined) {\n                buckets[hashes[i]] = [node.children[i]];\n            }\n            else {\n                buckets[hashes[i]].push(node.children[i]);\n            }\n        }\n        for (const k of keys(buckets)) {\n            if (buckets[k].length > 1) {\n                this.setModified();\n                this.mergeNodes(node, buckets[k]);\n            }\n        }\n    }\n}\n/**\n * Optimizer that removes identifier nodes that are not needed for selections.\n */\nexport class RemoveUnnecessaryIdentifierNodes extends TopDownOptimizer {\n    constructor(model) {\n        super();\n        this.requiresSelectionId = model && requiresSelectionId(model);\n    }\n    run(node) {\n        if (node instanceof IdentifierNode) {\n            // Only preserve IdentifierNodes if we have default discrete selections\n            // in our model tree, and if the nodes come after tuple producing nodes.\n            if (!(this.requiresSelectionId &&\n                (isDataSourceNode(node.parent) || node.parent instanceof AggregateNode || node.parent instanceof ParseNode))) {\n                this.setModified();\n                node.remove();\n            }\n        }\n    }\n}\n/**\n * Removes duplicate time unit nodes (as determined by the name of the output field) that may be generated due to\n * selections projected over time units. Only keeps the first time unit in any branch.\n *\n * This optimizer is a custom top down optimizer that keep track of produced fields in a branch.\n */\nexport class RemoveDuplicateTimeUnits extends Optimizer {\n    optimize(node) {\n        this.run(node, new Set());\n        return this.modifiedFlag;\n    }\n    run(node, timeUnitFields) {\n        let producedFields = new Set();\n        if (node instanceof TimeUnitNode) {\n            producedFields = node.producedFields();\n            if (hasIntersection(producedFields, timeUnitFields)) {\n                this.setModified();\n                node.removeFormulas(timeUnitFields);\n                if (node.producedFields.length === 0) {\n                    node.remove();\n                }\n            }\n        }\n        for (const child of node.children) {\n            this.run(child, new Set([...timeUnitFields, ...producedFields]));\n        }\n    }\n}\n/**\n * Remove output nodes that are not required.\n */\nexport class RemoveUnnecessaryOutputNodes extends TopDownOptimizer {\n    constructor() {\n        super();\n    }\n    run(node) {\n        if (node instanceof OutputNode && !node.isRequired()) {\n            this.setModified();\n            node.remove();\n        }\n    }\n}\n/**\n * Move parse nodes up to forks and merges them if possible.\n */\nexport class MoveParseUp extends BottomUpOptimizer {\n    run(node) {\n        if (isDataSourceNode(node)) {\n            return;\n        }\n        if (node.numChildren() > 1) {\n            // Don't move parse further up but continue with parent.\n            return;\n        }\n        for (const child of node.children) {\n            if (child instanceof ParseNode) {\n                if (node instanceof ParseNode) {\n                    this.setModified();\n                    node.merge(child);\n                }\n                else {\n                    // Don't swap with nodes that produce something that the parse node depends on (e.g. lookup).\n                    if (fieldIntersection(node.producedFields(), child.dependentFields())) {\n                        continue;\n                    }\n                    this.setModified();\n                    child.swapWithParent();\n                }\n            }\n        }\n        return;\n    }\n}\n/**\n * Inserts an intermediate ParseNode containing all non-conflicting parse fields and removes the empty ParseNodes.\n *\n * We assume that dependent paths that do not have a parse node can be just merged.\n */\nexport class MergeParse extends BottomUpOptimizer {\n    run(node) {\n        const originalChildren = [...node.children];\n        const parseChildren = node.children.filter((child) => child instanceof ParseNode);\n        if (node.numChildren() > 1 && parseChildren.length >= 1) {\n            const commonParse = {};\n            const conflictingParse = new Set();\n            for (const parseNode of parseChildren) {\n                const parse = parseNode.parse;\n                for (const k of keys(parse)) {\n                    if (!(k in commonParse)) {\n                        commonParse[k] = parse[k];\n                    }\n                    else if (commonParse[k] !== parse[k]) {\n                        conflictingParse.add(k);\n                    }\n                }\n            }\n            for (const field of conflictingParse) {\n                delete commonParse[field];\n            }\n            if (!isEmpty(commonParse)) {\n                this.setModified();\n                const mergedParseNode = new ParseNode(node, commonParse);\n                for (const childNode of originalChildren) {\n                    if (childNode instanceof ParseNode) {\n                        for (const key of keys(commonParse)) {\n                            delete childNode.parse[key];\n                        }\n                    }\n                    node.removeChild(childNode);\n                    childNode.parent = mergedParseNode;\n                    // remove empty parse nodes\n                    if (childNode instanceof ParseNode && keys(childNode.parse).length === 0) {\n                        childNode.remove();\n                    }\n                }\n            }\n        }\n    }\n}\n/**\n * Repeatedly remove leaf nodes that are not output or facet nodes.\n * The reason is that we don't need subtrees that don't have any output nodes.\n * Facet nodes are needed for the row or column domains.\n */\nexport class RemoveUnusedSubtrees extends BottomUpOptimizer {\n    run(node) {\n        if (node instanceof OutputNode || node.numChildren() > 0 || node instanceof FacetNode) {\n            // no need to continue with parent because it is output node or will have children (there was a fork)\n        }\n        else if (node instanceof SourceNode) {\n            // ignore empty unused sources as they will be removed in optimizationDataflowHelper\n        }\n        else {\n            this.setModified();\n            node.remove();\n        }\n    }\n}\n/**\n * Merge adjacent time unit nodes.\n */\nexport class MergeTimeUnits extends BottomUpOptimizer {\n    run(node) {\n        const timeUnitChildren = node.children.filter((x) => x instanceof TimeUnitNode);\n        const combination = timeUnitChildren.pop();\n        for (const timeUnit of timeUnitChildren) {\n            this.setModified();\n            combination.merge(timeUnit);\n        }\n    }\n}\nexport class MergeAggregates extends BottomUpOptimizer {\n    run(node) {\n        const aggChildren = node.children.filter((child) => child instanceof AggregateNode);\n        // Object which we'll use to map the fields which an aggregate is grouped by to\n        // the set of aggregates with that grouping. This is useful as only aggregates\n        // with the same group by can be merged\n        const groupedAggregates = {};\n        // Build groupedAggregates\n        for (const agg of aggChildren) {\n            const groupBys = hash(agg.groupBy);\n            if (!(groupBys in groupedAggregates)) {\n                groupedAggregates[groupBys] = [];\n            }\n            groupedAggregates[groupBys].push(agg);\n        }\n        // Merge aggregateNodes with same key in groupedAggregates\n        for (const group of keys(groupedAggregates)) {\n            const mergeableAggs = groupedAggregates[group];\n            if (mergeableAggs.length > 1) {\n                const mergedAggs = mergeableAggs.pop();\n                for (const agg of mergeableAggs) {\n                    if (mergedAggs.merge(agg)) {\n                        node.removeChild(agg);\n                        agg.parent = mergedAggs;\n                        agg.remove();\n                        this.setModified();\n                    }\n                }\n            }\n        }\n    }\n}\n/**\n * Merge bin nodes and move them up through forks. Stop at filters, parse, identifier as we want them to stay before the bin node.\n */\nexport class MergeBins extends BottomUpOptimizer {\n    constructor(model) {\n        super();\n        this.model = model;\n    }\n    run(node) {\n        const moveBinsUp = !(isDataSourceNode(node) ||\n            node instanceof FilterNode ||\n            node instanceof ParseNode ||\n            node instanceof IdentifierNode);\n        const promotableBins = [];\n        const remainingBins = [];\n        for (const child of node.children) {\n            if (child instanceof BinNode) {\n                if (moveBinsUp && !fieldIntersection(node.producedFields(), child.dependentFields())) {\n                    promotableBins.push(child);\n                }\n                else {\n                    remainingBins.push(child);\n                }\n            }\n        }\n        if (promotableBins.length > 0) {\n            const promotedBin = promotableBins.pop();\n            for (const bin of promotableBins) {\n                promotedBin.merge(bin, this.model.renameSignal.bind(this.model));\n            }\n            this.setModified();\n            if (node instanceof BinNode) {\n                node.merge(promotedBin, this.model.renameSignal.bind(this.model));\n            }\n            else {\n                promotedBin.swapWithParent();\n            }\n        }\n        if (remainingBins.length > 1) {\n            const remainingBin = remainingBins.pop();\n            for (const bin of remainingBins) {\n                remainingBin.merge(bin, this.model.renameSignal.bind(this.model));\n            }\n            this.setModified();\n        }\n    }\n}\n/**\n * This optimizer takes output nodes that are at a fork and moves them before the fork.\n *\n * The algorithm iterates over the children and tries to find the last output node in a chain of output nodes.\n * It then moves all output nodes before that main output node. All other children (and the children of the output nodes)\n * are inserted after the main output node.\n */\nexport class MergeOutputs extends BottomUpOptimizer {\n    run(node) {\n        const children = [...node.children];\n        const hasOutputChild = some(children, child => child instanceof OutputNode);\n        if (!hasOutputChild || node.numChildren() <= 1) {\n            return;\n        }\n        const otherChildren = [];\n        // The output node we will connect all other nodes to.\n        // Output nodes will be added before the new node, other nodes after.\n        let mainOutput;\n        for (const child of children) {\n            if (child instanceof OutputNode) {\n                let lastOutput = child;\n                while (lastOutput.numChildren() === 1) {\n                    const [theChild] = lastOutput.children;\n                    if (theChild instanceof OutputNode) {\n                        lastOutput = theChild;\n                    }\n                    else {\n                        break;\n                    }\n                }\n                otherChildren.push(...lastOutput.children);\n                if (mainOutput) {\n                    // Move the output nodes before the mainOutput. We do this by setting\n                    // the parent of the first not to the parent of the main output and\n                    // the main output's parent to the last output.\n                    // note: the child is the first output\n                    node.removeChild(child);\n                    child.parent = mainOutput.parent;\n                    mainOutput.parent.removeChild(mainOutput);\n                    mainOutput.parent = lastOutput;\n                    this.setModified();\n                }\n                else {\n                    mainOutput = lastOutput;\n                }\n            }\n            else {\n                otherChildren.push(child);\n            }\n        }\n        if (otherChildren.length) {\n            this.setModified();\n            for (const child of otherChildren) {\n                child.parent.removeChild(child);\n                child.parent = mainOutput;\n            }\n        }\n    }\n}\n//# sourceMappingURL=optimizers.js.map"]},"metadata":{},"sourceType":"module"}